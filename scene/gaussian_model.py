#
# Copyright (C) 2023, Inria
# GRAPHDECO research group, https://team.inria.fr/graphdeco
# All rights reserved.
#
# This software is free for non-commercial, research and evaluation use 
# under the terms of the LICENSE.md file.
#
# For inquiries contact  george.drettakis@inria.fr
#

import torch
import numpy as np
from utils.general_utils import inverse_sigmoid, get_expon_lr_func, build_rotation, identity_gate
from torch import nn
import os
from utils.system_utils import mkdir_p
from plyfile import PlyData, PlyElement
from utils.sh_utils import RGB2SH
from simple_knn._C import distCUDA2
from utils.graphics_utils import BasicPointCloud
from utils.general_utils import strip_symmetric, build_scaling_rotation

try:
    from diff_gaussian_rasterization import SparseGaussianAdam
except:
    pass

class GaussianModel:

    def setup_functions(self):
        def build_covariance_from_scaling_rotation(scaling, scaling_modifier, rotation):
            L = build_scaling_rotation(scaling_modifier * scaling, rotation)
            actual_covariance = L @ L.transpose(1, 2)
            symm = strip_symmetric(actual_covariance)
            return symm
        
        self.scaling_activation = torch.exp
        self.scaling_inverse_activation = torch.log

        self.covariance_activation = build_covariance_from_scaling_rotation
        self.opacity_activation = torch.sigmoid
        self.inverse_opacity_activation = inverse_sigmoid

        self.rotation_activation = torch.nn.functional.normalize

    def modify_functions(self):
        old_opacities = self.get_opacity.clone()
        self.opacity_activation = torch.abs
        self.inverse_opacity_activation = identity_gate
        self._opacity = self.opacity_activation(old_opacities)

    def __init__(self, sh_degree, optimizer_type="default"):
        self.active_sh_degree = 0
        self.optimizer_type = optimizer_type
        self.max_sh_degree = sh_degree  
        self._xyz = torch.empty(0)
        self._features_dc = torch.empty(0)
        self._features_rest = torch.empty(0)
        self._scaling = torch.empty(0)
        self._rotation = torch.empty(0)
        self._opacity = torch.empty(0)
        self.max_radii2D = torch.empty(0)
        self.xyz_gradient_accum = torch.empty(0)
        self.xyz_gradient_accum_abs = torch.empty(0)
        self.denom = torch.empty(0)
        self.optimizer = None
        self.shoptimizer = None
        self.percent_dense = 0
        self.spatial_lr_scale = 0
        self.tmp_radii = None
        self.train_cameras = None  # ç”¨äºéšæœºåˆå§‹åŒ–çš„ç›¸æœºåˆ—è¡¨
        self.setup_functions()

    def capture(self, optimizer_type):
        if optimizer_type == "default":
            return (
            self.active_sh_degree,
            self._xyz,
            self._features_dc,
            self._features_rest,
            self._scaling,
            self._rotation,
            self._opacity,
            self.max_radii2D,
            self.xyz_gradient_accum,
            self.xyz_gradient_accum_abs,
            self.denom,
            self.optimizer.state_dict(),
            self.shoptimizer.state_dict(),
            self.spatial_lr_scale,
        )
        else:
            return (
            self.active_sh_degree,
            self._xyz,
            self._features_dc,
            self._features_rest,
            self._scaling,
            self._rotation,
            self._opacity,
            self.max_radii2D,
            self.xyz_gradient_accum,
            self.xyz_gradient_accum_abs,
            self.denom,
            self.optimizer.state_dict(),
            self.spatial_lr_scale,
        )
    
    def restore(self, model_args, training_args):
        (self.active_sh_degree, 
        self._xyz, 
        self._features_dc, 
        self._features_rest,
        self._scaling, 
        self._rotation, 
        self._opacity,
        self.max_radii2D, 
        xyz_gradient_accum,
        xyz_gradient_accum_abs, 
        denom,
        opt_dict, 
        shopt_dict,
        self.spatial_lr_scale) = model_args
        self.training_setup(training_args)
        self.xyz_gradient_accum = xyz_gradient_accum
        self.xyz_gradient_accum_abs = xyz_gradient_accum_abs
        self.denom = denom
        self.optimizer.load_state_dict(opt_dict)
        self.shoptimizer.load_state_dict(shopt_dict)

    @property
    def get_scaling(self):
        return self.scaling_activation(self._scaling)
    
    @property
    def get_rotation(self):
        return self.rotation_activation(self._rotation)
    
    @property
    def get_xyz(self):
        return self._xyz
    
    @property
    def get_features(self):
        features_dc = self._features_dc
        features_rest = self._features_rest
        return torch.cat((features_dc, features_rest), dim=1)
    
    @property
    def get_features_dc(self):
        return self._features_dc
    
    @property
    def get_features_rest(self):
        return self._features_rest
    
    @property
    def get_opacity(self):
        return self.opacity_activation(self._opacity)
    
    def get_covariance(self, scaling_modifier = 1):
        return self.covariance_activation(self.get_scaling, scaling_modifier, self._rotation)

    def oneupSHdegree(self):
        if self.active_sh_degree < self.max_sh_degree:
            self.active_sh_degree += 1

    def create_from_pcd(self, pcd : BasicPointCloud, spatial_lr_scale : float):
        self.spatial_lr_scale = spatial_lr_scale
        fused_point_cloud = torch.tensor(np.asarray(pcd.points)).float().cuda()
        fused_color = RGB2SH(torch.tensor(np.asarray(pcd.colors)).float().cuda())
        features = torch.zeros((fused_color.shape[0], 3, (self.max_sh_degree + 1) ** 2)).float().cuda()
        features[:, :3, 0 ] = fused_color
        features[:, 3:, 1:] = 0.0

        print("Number of points at initialisation : ", fused_point_cloud.shape[0])

        dist2 = torch.clamp_min(distCUDA2(torch.from_numpy(np.asarray(pcd.points)).float().cuda()), 0.0000001)
        scales = torch.log(torch.sqrt(dist2))[...,None].repeat(1, 3)
        rots = torch.zeros((fused_point_cloud.shape[0], 4), device="cuda")
        rots[:, 0] = 1

        opacities = self.inverse_opacity_activation(0.1 * torch.ones((fused_point_cloud.shape[0], 1), dtype=torch.float, device="cuda"))

        self._xyz = nn.Parameter(fused_point_cloud.requires_grad_(True))
        self._features_dc = nn.Parameter(features[:,:,0:1].transpose(1, 2).contiguous().requires_grad_(True))
        self._features_rest = nn.Parameter(features[:,:,1:].transpose(1, 2).contiguous().requires_grad_(True))
        self._scaling = nn.Parameter(scales.requires_grad_(True))
        self._rotation = nn.Parameter(rots.requires_grad_(True))
        self._opacity = nn.Parameter(opacities.requires_grad_(True))
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")

    def create_random_initialization(self, num_points=100, spatial_lr_scale=1.0):
        """
        åˆ›å»ºéšæœºåˆå§‹åŒ–çš„ç‚¹äº‘ï¼Œç”¨äºæ²¡æœ‰æä¾›PLYæ–‡ä»¶çš„æƒ…å†µ
        
        Args:
            num_points: åˆå§‹é«˜æ–¯ç‚¹æ•°é‡
            spatial_lr_scale: ç©ºé—´å­¦ä¹ ç‡ç¼©æ”¾å› å­
        """
        self.spatial_lr_scale = spatial_lr_scale

        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸æœºä¿¡æ¯å¯ç”¨
        if hasattr(self, 'train_cameras') and self.train_cameras is not None and len(self.train_cameras) > 0:
            print(f"\nğŸ“· Creating initial Gaussian model from camera frustums with {num_points} points")
            points = self._sample_from_camera_frustums(self.train_cameras, num_points)
            
            # æ·»åŠ åˆå§‹åŒ–ç‚¹ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š åˆå§‹åŒ–ç‚¹ç»Ÿè®¡:")
            points_np = points.cpu().numpy()
            print(f"  - ç‚¹æ•°: {num_points}")
            print(f"  - XèŒƒå›´: [{points_np[:,0].min():.4f}, {points_np[:,0].max():.4f}] (è·¨åº¦: {points_np[:,0].max() - points_np[:,0].min():.4f})")
            print(f"  - YèŒƒå›´: [{points_np[:,1].min():.4f}, {points_np[:,1].max():.4f}] (è·¨åº¦: {points_np[:,1].max() - points_np[:,1].min():.4f})")
            print(f"  - ZèŒƒå›´: [{points_np[:,2].min():.4f}, {points_np[:,2].max():.4f}] (è·¨åº¦: {points_np[:,2].max() - points_np[:,2].min():.4f})")
        else:
            print(f"\nğŸ“· Creating random initial Gaussian model with {num_points} points (scene-based)")
            # å›é€€åˆ°åŸºäºåœºæ™¯èŒƒå›´çš„éšæœºé‡‡æ ·
            scale = spatial_lr_scale * 0.5
            points = (torch.rand((num_points, 3), device="cuda") * 2 - 1) * scale

        # éšæœºé¢œè‰²ï¼ˆè½¬æ¢ä¸ºSHç³»æ•°ï¼‰
        random_colors = torch.rand((num_points, 3), device="cuda")
        fused_color = RGB2SH(random_colors)
        features = torch.zeros((fused_color.shape[0], 3, (self.max_sh_degree + 1) ** 2)).float().cuda()
        features[:, :3, 0] = fused_color
        features[:, 3:, 1:] = 0.0

        # éšæœºç¼©æ”¾ - ä½¿ç”¨è¾ƒå°çš„åˆå§‹å€¼
        random_scales = torch.rand((num_points, 3), device="cuda") * 0.01 * spatial_lr_scale * 0.1
        random_scales = torch.clamp(random_scales, min=1e-6, max=1.0)  # é˜²æ­¢æç«¯å€¼
        scales = torch.log(random_scales)

        # éšæœºæ—‹è½¬ï¼ˆå½’ä¸€åŒ–çš„å››å…ƒæ•°ï¼‰
        rots = torch.randn((num_points, 4), device="cuda")
        rots = rots / torch.norm(rots, dim=1, keepdim=True)

        # éšæœºä¸é€æ˜åº¦ï¼ˆä½¿ç”¨inverse_sigmoidå˜æ¢ï¼‰
        opacities = self.inverse_opacity_activation(
            0.5 * torch.ones((num_points, 1), dtype=torch.float, device="cuda"))

        self._xyz = nn.Parameter(points.requires_grad_(True))
        self._features_dc = nn.Parameter(features[:, :, 0:1].transpose(1, 2).contiguous().requires_grad_(True))
        self._features_rest = nn.Parameter(features[:, :, 1:].transpose(1, 2).contiguous().requires_grad_(True))
        self._scaling = nn.Parameter(scales.requires_grad_(True))
        self._rotation = nn.Parameter(rots.requires_grad_(True))
        self._opacity = nn.Parameter(opacities.requires_grad_(True))
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")
        
        print(f"\nâœ… Random initialization complete: {num_points} points created")
        print(f"  - ç¼©æ”¾å€¼èŒƒå›´: [{torch.exp(scales).min():.6f}, {torch.exp(scales).max():.6f}]")
        print(f"  - ä¸é€æ˜åº¦èŒƒå›´: [{torch.sigmoid(opacities).min():.4f}, {torch.sigmoid(opacities).max():.4f}]")

    def _sample_from_camera_frustums(self, cameras, num_points):
        """åœ¨ç›¸æœºè§†é”¥ä½“å†…é‡‡æ ·ç‚¹"""
        import numpy as np
        
        points_list = []
        num_cameras = len(cameras)
        
        if num_cameras < 2:
            print("Warning: Less than 2 cameras available, falling back to simple random sampling")
            scale = self.spatial_lr_scale * 0.5
            return (torch.rand((num_points, 3), device="cuda") * 2 - 1) * scale

        # æ”¶é›†ç›¸æœºå‚æ•°
        cam_data = []
        for i, cam in enumerate(cameras):
            try:
                # è·å–ç›¸æœºä½ç½®
                if hasattr(cam, 'camera_center') and cam.camera_center is not None:
                    pos = cam.camera_center
                    if not isinstance(pos, torch.Tensor):
                        pos = torch.tensor(pos, device="cuda", dtype=torch.float32)
                elif hasattr(cam, 'T') and cam.T is not None:
                    # ä» R å’Œ T è®¡ç®—ç›¸æœºä¸­å¿ƒ
                    if hasattr(cam, 'R') and cam.R is not None:
                        R = cam.R if isinstance(cam.R, torch.Tensor) else torch.tensor(cam.R, device="cuda", dtype=torch.float32)
                        T = cam.T if isinstance(cam.T, torch.Tensor) else torch.tensor(cam.T, device="cuda", dtype=torch.float32)
                        # ç›¸æœºä¸­å¿ƒ = -R^T * T
                        pos = -torch.mm(R.T, T.reshape(-1, 1)).reshape(-1)
                    else:
                        T = cam.T if isinstance(cam.T, torch.Tensor) else torch.tensor(cam.T, device="cuda", dtype=torch.float32)
                        pos = T  # è¿‘ä¼¼ä½¿ç”¨å¹³ç§»å‘é‡ä½œä¸ºä½ç½®
                else:
                    continue
                
                # è·å–ç›¸æœºæœå‘
                if hasattr(cam, 'R') and cam.R is not None:
                    R = cam.R if isinstance(cam.R, torch.Tensor) else torch.tensor(cam.R, device="cuda", dtype=torch.float32)
                    # åœ¨COLMAP/OpenCVçº¦å®šä¸­ï¼Œç›¸æœºæœå‘æ˜¯ -Rçš„ç¬¬ä¸‰åˆ—
                    forward = -R[:, 2]
                    forward = forward / (torch.norm(forward) + 1e-8)
                    
                    # è®¡ç®—å³å‘é‡å’Œä¸Šå‘é‡
                    world_up = torch.tensor([0, -1, 0], device="cuda", dtype=torch.float32)  # å‡è®¾Yè½´å‘ä¸‹
                    right = torch.cross(forward, world_up)
                    right = right / (torch.norm(right) + 1e-8)
                    up = torch.cross(right, forward)
                    up = up / (torch.norm(up) + 1e-8)
                else:
                    # å¦‚æœæ²¡æœ‰æ—‹è½¬çŸ©é˜µï¼Œä½¿ç”¨é»˜è®¤æœå‘
                    forward = torch.tensor([0, 0, 1], device="cuda", dtype=torch.float32)
                    right = torch.tensor([1, 0, 0], device="cuda", dtype=torch.float32)
                    up = torch.tensor([0, -1, 0], device="cuda", dtype=torch.float32)
                
                # è·å–FOV
                if hasattr(cam, 'FovX') and cam.FovX is not None:
                    fov_x = float(cam.FovX)
                elif hasattr(cam, 'fovx'):
                    fov_x = float(cam.fovx)
                else:
                    fov_x = np.pi / 3  # é»˜è®¤60åº¦
                
                if hasattr(cam, 'FovY') and cam.FovY is not None:
                    fov_y = float(cam.FovY)
                elif hasattr(cam, 'fovy'):
                    fov_y = float(cam.fovy)
                else:
                    fov_y = np.pi / 3
                
                cam_data.append({
                    'position': pos,
                    'forward': forward,
                    'right': right,
                    'up': up,
                    'fov_x': fov_x,
                    'fov_y': fov_y
                })
                
            except Exception as e:
                print(f"Warning: Error processing camera {i}: {e}")
                continue
        
        if len(cam_data) < 2:
            print("Warning: Insufficient valid camera data, falling back to simple random sampling")
            scale = self.spatial_lr_scale * 0.5
            return (torch.rand((num_points, 3), device="cuda") * 2 - 1) * scale
        
        print(f"  - æˆåŠŸå¤„ç† {len(cam_data)}/{num_cameras} ä¸ªç›¸æœº")
        
        # åœ¨è§†é”¥ä½“å†…é‡‡æ ·ç‚¹
        for i in range(num_points):
            try:
                # éšæœºé€‰æ‹©ä¸€ä¸ªç›¸æœº
                cam_idx = np.random.randint(0, len(cam_data))
                cam = cam_data[cam_idx]
                
                # åœ¨è§†é”¥ä½“å†…é‡‡æ ·
                # 1. éšæœºæ·±åº¦ï¼ˆåœ¨åˆç†èŒƒå›´å†…ï¼‰
                depth = torch.rand(1, device="cuda") * self.spatial_lr_scale * 0.8 + 0.1 * self.spatial_lr_scale
                
                # 2. éšæœºæ–¹å‘åç§»ï¼ˆåœ¨FOVå†…ï¼‰
                max_offset_x = torch.tan(torch.tensor(cam['fov_x'] / 2, device="cuda"))
                max_offset_y = torch.tan(torch.tensor(cam['fov_y'] / 2, device="cuda"))
                
                offset_x = (torch.rand(1, device="cuda") * 2 - 1) * max_offset_x
                offset_y = (torch.rand(1, device="cuda") * 2 - 1) * max_offset_y
                
                # 3. è®¡ç®—ç›¸æœºå±€éƒ¨åæ ‡
                point = cam['position'] + depth * cam['forward'] + depth * offset_x * cam['right'] + depth * offset_y * cam['up']
                
                # æ·»åŠ å°‘é‡å™ªå£°
                noise = torch.randn(3, device="cuda") * 0.1 * self.spatial_lr_scale
                point = point + noise
                
                points_list.append(point)
                
            except Exception as e:
                print(f"Warning: Error sampling point {i}: {e}")
                # å¦‚æœå‡ºé”™ï¼Œä½¿ç”¨ç®€å•çš„éšæœºç‚¹
                point = torch.randn(3, device="cuda") * self.spatial_lr_scale * 0.5
                points_list.append(point)
        
        points = torch.stack(points_list)
        
        # æ‰“å°é‡‡æ ·ç»Ÿè®¡
        print(f"  - é‡‡æ ·ç‚¹èŒƒå›´: X [{points[:,0].min():.2f}, {points[:,0].max():.2f}]")
        print(f"                Y [{points[:,1].min():.2f}, {points[:,1].max():.2f}]")
        print(f"                Z [{points[:,2].min():.2f}, {points[:,2].max():.2f}]")
        
        return points

    def training_setup(self, training_args):
        self.percent_dense = training_args.percent_dense
        self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.xyz_gradient_accum_abs = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.denom = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")

        l = [
            {'params': [self._xyz], 'lr': training_args.position_lr_init * self.spatial_lr_scale, "name": "xyz"},
            {'params': [self._features_dc], 'lr': training_args.lowfeature_lr, "name": "f_dc"},
            {'params': [self._opacity], 'lr': training_args.opacity_lr, "name": "opacity"},
            {'params': [self._scaling], 'lr': training_args.scaling_lr, "name": "scaling"},
            {'params': [self._rotation], 'lr': training_args.rotation_lr, "name": "rotation"}
        ]
        sh_l = [{'params': [self._features_rest], 'lr': training_args.highfeature_lr / 20.0, "name": "f_rest"}]

        if self.optimizer_type == "default":
            self.optimizer = torch.optim.Adam(l, lr=0.0, eps=1e-15)
            self.shoptimizer = torch.optim.Adam(sh_l, lr=0.0, eps=1e-15)
        elif self.optimizer_type == "sparse_adam":
            self.optimizer = SparseGaussianAdam(l + sh_l, lr=0.0, eps=1e-15)
        self.xyz_scheduler_args = get_expon_lr_func(lr_init=training_args.position_lr_init*self.spatial_lr_scale,
                                                    lr_final=training_args.position_lr_final*self.spatial_lr_scale,
                                                    lr_delay_mult=training_args.position_lr_delay_mult,
                                                    max_steps=training_args.position_lr_max_steps)

    def update_learning_rate(self, iteration):
        ''' Learning rate scheduling per step '''
        for param_group in self.optimizer.param_groups:
            if param_group["name"] == "xyz":
                lr = self.xyz_scheduler_args(iteration)
                param_group['lr'] = lr
                return lr

    def optimizer_step(self, iteration):
        ''' An optimization schdeuler. The goal is similar to the sparse Adam of taming 3dgs.'''
        if iteration <= 15000:
            self.optimizer.step()
            self.optimizer.zero_grad(set_to_none = True)
            if iteration % 16 == 0:
                self.shoptimizer.step()
                self.shoptimizer.zero_grad(set_to_none = True)
        elif iteration <= 20000:
            if iteration % 32 ==0:
                self.optimizer.step()
                self.optimizer.zero_grad(set_to_none = True)
                self.shoptimizer.step()
                self.shoptimizer.zero_grad(set_to_none = True)
        else:
            if iteration % 64 ==0:
                self.optimizer.step()
                self.optimizer.zero_grad(set_to_none = True)
                self.shoptimizer.step()
                self.shoptimizer.zero_grad(set_to_none = True)

    def construct_list_of_attributes(self):
        l = ['x', 'y', 'z', 'nx', 'ny', 'nz']
        # All channels except the 3 DC
        for i in range(self._features_dc.shape[1]*self._features_dc.shape[2]):
            l.append('f_dc_{}'.format(i))
        for i in range(self._features_rest.shape[1]*self._features_rest.shape[2]):
            l.append('f_rest_{}'.format(i))
        l.append('opacity')
        for i in range(self._scaling.shape[1]):
            l.append('scale_{}'.format(i))
        for i in range(self._rotation.shape[1]):
            l.append('rot_{}'.format(i))
        return l

    def save_ply(self, path):
        mkdir_p(os.path.dirname(path))

        xyz = self._xyz.detach().cpu().numpy()
        normals = np.zeros_like(xyz)
        f_dc = self._features_dc.detach().transpose(1, 2).flatten(start_dim=1).contiguous().cpu().numpy()
        f_rest = self._features_rest.detach().transpose(1, 2).flatten(start_dim=1).contiguous().cpu().numpy()
        opacities = self._opacity.detach().cpu().numpy()
        scale = self._scaling.detach().cpu().numpy()
        rotation = self._rotation.detach().cpu().numpy()

        dtype_full = [(attribute, 'f4') for attribute in self.construct_list_of_attributes()]

        elements = np.empty(xyz.shape[0], dtype=dtype_full)
        attributes = np.concatenate((xyz, normals, f_dc, f_rest, opacities, scale, rotation), axis=1)
        elements[:] = list(map(tuple, attributes))
        el = PlyElement.describe(elements, 'vertex')
        PlyData([el]).write(path)

    def reset_opacity(self):
        opacities_new = self.inverse_opacity_activation(torch.min(self.get_opacity, torch.ones_like(self.get_opacity)*0.01))
        optimizable_tensors = self.replace_tensor_to_optimizer(opacities_new, "opacity")
        self._opacity = optimizable_tensors["opacity"]

    def load_ply(self, path):
        plydata = PlyData.read(path)

        xyz = np.stack((np.asarray(plydata.elements[0]["x"]),
                        np.asarray(plydata.elements[0]["y"]),
                        np.asarray(plydata.elements[0]["z"])),  axis=1)
        opacities = np.asarray(plydata.elements[0]["opacity"])[..., np.newaxis]

        features_dc = np.zeros((xyz.shape[0], 3, 1))
        features_dc[:, 0, 0] = np.asarray(plydata.elements[0]["f_dc_0"])
        features_dc[:, 1, 0] = np.asarray(plydata.elements[0]["f_dc_1"])
        features_dc[:, 2, 0] = np.asarray(plydata.elements[0]["f_dc_2"])

        extra_f_names = [p.name for p in plydata.elements[0].properties if p.name.startswith("f_rest_")]
        extra_f_names = sorted(extra_f_names, key = lambda x: int(x.split('_')[-1]))
        assert len(extra_f_names)==3*(self.max_sh_degree + 1) ** 2 - 3
        features_extra = np.zeros((xyz.shape[0], len(extra_f_names)))
        for idx, attr_name in enumerate(extra_f_names):
            features_extra[:, idx] = np.asarray(plydata.elements[0][attr_name])
        # Reshape (P,F*SH_coeffs) to (P, F, SH_coeffs except DC)
        features_extra = features_extra.reshape((features_extra.shape[0], 3, (self.max_sh_degree + 1) ** 2 - 1))

        scale_names = [p.name for p in plydata.elements[0].properties if p.name.startswith("scale_")]
        scale_names = sorted(scale_names, key = lambda x: int(x.split('_')[-1]))
        scales = np.zeros((xyz.shape[0], len(scale_names)))
        for idx, attr_name in enumerate(scale_names):
            scales[:, idx] = np.asarray(plydata.elements[0][attr_name])

        rot_names = [p.name for p in plydata.elements[0].properties if p.name.startswith("rot")]
        rot_names = sorted(rot_names, key = lambda x: int(x.split('_')[-1]))
        rots = np.zeros((xyz.shape[0], len(rot_names)))
        for idx, attr_name in enumerate(rot_names):
            rots[:, idx] = np.asarray(plydata.elements[0][attr_name])

        self._xyz = nn.Parameter(torch.tensor(xyz, dtype=torch.float, device="cuda").requires_grad_(True))
        self._features_dc = nn.Parameter(torch.tensor(features_dc, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(True))
        self._features_rest = nn.Parameter(torch.tensor(features_extra, dtype=torch.float, device="cuda").transpose(1, 2).contiguous().requires_grad_(True))
        self._opacity = nn.Parameter(torch.tensor(opacities, dtype=torch.float, device="cuda").requires_grad_(True))
        self._scaling = nn.Parameter(torch.tensor(scales, dtype=torch.float, device="cuda").requires_grad_(True))
        self._rotation = nn.Parameter(torch.tensor(rots, dtype=torch.float, device="cuda").requires_grad_(True))

        self.active_sh_degree = self.max_sh_degree

    def replace_tensor_to_optimizer(self, tensor, name):
        optimizable_tensors = {}
        for group in self.optimizer.param_groups:
            if group["name"] == name:
                stored_state = self.optimizer.state.get(group['params'][0], None)
                stored_state["exp_avg"] = torch.zeros_like(tensor)
                stored_state["exp_avg_sq"] = torch.zeros_like(tensor)

                del self.optimizer.state[group['params'][0]]
                group["params"][0] = nn.Parameter(tensor.requires_grad_(True))
                self.optimizer.state[group['params'][0]] = stored_state

                optimizable_tensors[group["name"]] = group["params"][0]
        return optimizable_tensors

    def _prune_optimizer(self, mask):
        optimizable_tensors = {}
        optimizers = [self.optimizer]
        if self.shoptimizer: optimizers.append(self.shoptimizer)

        for opt in optimizers:
            for group in opt.param_groups:
                stored_state = opt.state.get(group['params'][0], None)
                if stored_state is not None:
                    stored_state["exp_avg"] = stored_state["exp_avg"][mask]
                    stored_state["exp_avg_sq"] = stored_state["exp_avg_sq"][mask]

                    del opt.state[group['params'][0]]
                    group["params"][0] = nn.Parameter((group["params"][0][mask].requires_grad_(True)))
                    opt.state[group['params'][0]] = stored_state

                    optimizable_tensors[group["name"]] = group["params"][0]
                else:
                    group["params"][0] = nn.Parameter(group["params"][0][mask].requires_grad_(True))
                    optimizable_tensors[group["name"]] = group["params"][0]
        return optimizable_tensors

    def prune_points(self, mask):
        valid_points_mask = ~mask
        optimizable_tensors = self._prune_optimizer(valid_points_mask)

        self._xyz = optimizable_tensors["xyz"]
        self._features_dc = optimizable_tensors["f_dc"]
        self._features_rest = optimizable_tensors["f_rest"]
        self._opacity = optimizable_tensors["opacity"]
        self._scaling = optimizable_tensors["scaling"]
        self._rotation = optimizable_tensors["rotation"]

        self.xyz_gradient_accum = self.xyz_gradient_accum[valid_points_mask]
        self.xyz_gradient_accum_abs = self.xyz_gradient_accum_abs[valid_points_mask]

        self.denom = self.denom[valid_points_mask]
        self.max_radii2D = self.max_radii2D[valid_points_mask]
        if self.tmp_radii is not None:
            self.tmp_radii = self.tmp_radii[valid_points_mask]

    def cat_tensors_to_optimizer(self, tensors_dict):
        optimizable_tensors = {}
        optimizers = [self.optimizer]
        if self.shoptimizer: optimizers.append(self.shoptimizer)

        for opt in optimizers:
            for group in opt.param_groups:
                assert len(group["params"]) == 1
                extension_tensor = tensors_dict[group["name"]]
                stored_state = opt.state.get(group['params'][0], None)
                if stored_state is not None:

                    stored_state["exp_avg"] = torch.cat((stored_state["exp_avg"], torch.zeros_like(extension_tensor)), dim=0)
                    stored_state["exp_avg_sq"] = torch.cat((stored_state["exp_avg_sq"], torch.zeros_like(extension_tensor)), dim=0)

                    del opt.state[group['params'][0]]
                    group["params"][0] = nn.Parameter(torch.cat((group["params"][0], extension_tensor), dim=0).requires_grad_(True))
                    opt.state[group['params'][0]] = stored_state

                    optimizable_tensors[group["name"]] = group["params"][0]
                else:
                    group["params"][0] = nn.Parameter(torch.cat((group["params"][0], extension_tensor), dim=0).requires_grad_(True))
                    optimizable_tensors[group["name"]] = group["params"][0]

        return optimizable_tensors

    def densification_postfix(self, new_xyz, new_features_dc, new_features_rest, new_opacities, new_scaling, new_rotation, new_tmp_radii):
        d = {"xyz": new_xyz,
        "f_dc": new_features_dc,
        "f_rest": new_features_rest,
        "opacity": new_opacities,
        "scaling" : new_scaling,
        "rotation" : new_rotation}

        optimizable_tensors = self.cat_tensors_to_optimizer(d)
        self._xyz = optimizable_tensors["xyz"]
        self._features_dc = optimizable_tensors["f_dc"]
        self._features_rest = optimizable_tensors["f_rest"]
        self._opacity = optimizable_tensors["opacity"]
        self._scaling = optimizable_tensors["scaling"]
        self._rotation = optimizable_tensors["rotation"]

        self.tmp_radii = torch.cat((self.tmp_radii, new_tmp_radii))
        self.xyz_gradient_accum = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.xyz_gradient_accum_abs = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")  # abs
        self.denom = torch.zeros((self.get_xyz.shape[0], 1), device="cuda")
        self.max_radii2D = torch.zeros((self.get_xyz.shape[0]), device="cuda")

    def densify_and_split_fastgs(self, metric_mask, filter, N=2):
        current_num = self.get_xyz.shape[0]
        
        # ç¡®ä¿ mask ç»´åº¦åŒ¹é…å½“å‰ç‚¹æ•°
        if metric_mask.shape[0] != current_num:
            if metric_mask.shape[0] < current_num:
                new_metric_mask = torch.zeros(current_num, dtype=bool, device="cuda")
                new_metric_mask[:metric_mask.shape[0]] = metric_mask
                metric_mask = new_metric_mask
            else:
                metric_mask = metric_mask[:current_num]
        
        if filter.shape[0] != current_num:
            if filter.shape[0] < current_num:
                new_filter = torch.zeros(current_num, dtype=bool, device="cuda")
                new_filter[:filter.shape[0]] = filter
                filter = new_filter
            else:
                filter = filter[:current_num]
        
        selected_pts_mask = torch.zeros((current_num), dtype=bool, device="cuda")
        mask = torch.logical_and(metric_mask, filter)
        
        if mask.shape[0] <= current_num:
            selected_pts_mask[:mask.shape[0]] = mask
        else:
            selected_pts_mask = mask[:current_num]

        if selected_pts_mask.sum() == 0:
            return

        stds = self.get_scaling[selected_pts_mask].repeat(N,1)
        means = torch.zeros((stds.size(0), 3), device="cuda")
        samples = torch.normal(mean=means, std=stds)
        rots = build_rotation(self._rotation[selected_pts_mask]).repeat(N,1,1)
        new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[selected_pts_mask].repeat(N, 1)
        new_scaling = self.scaling_inverse_activation(self.get_scaling[selected_pts_mask].repeat(N,1) / (0.8*N))
        new_rotation = self._rotation[selected_pts_mask].repeat(N,1)
        new_features_dc = self._features_dc[selected_pts_mask].repeat(N,1,1)
        new_features_rest = self._features_rest[selected_pts_mask].repeat(N,1,1)
        new_opacity = self._opacity[selected_pts_mask].repeat(N,1)
        
        # ç¡®ä¿ tmp_radii å­˜åœ¨ä¸”ç»´åº¦æ­£ç¡®
        if self.tmp_radii is None:
            self.tmp_radii = torch.zeros(current_num, device="cuda")
        elif self.tmp_radii.shape[0] != current_num:
            new_tmp_radii = torch.zeros(current_num, device="cuda")
            copy_len = min(self.tmp_radii.shape[0], current_num)
            new_tmp_radii[:copy_len] = self.tmp_radii[:copy_len]
            self.tmp_radii = new_tmp_radii
        
        new_tmp_radii = self.tmp_radii[selected_pts_mask].repeat(N)

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest, 
                                  new_opacity, new_scaling, new_rotation, new_tmp_radii)

        prune_filter = torch.cat((selected_pts_mask, torch.zeros(N * selected_pts_mask.sum(), device="cuda", dtype=bool)))
        self.prune_points(prune_filter)

    def densify_and_clone_fastgs(self, metric_mask, filter):
        current_num = self.get_xyz.shape[0]
        
        # ç¡®ä¿ mask ç»´åº¦åŒ¹é…å½“å‰ç‚¹æ•°
        if metric_mask.shape[0] != current_num:
            if metric_mask.shape[0] < current_num:
                new_metric_mask = torch.zeros(current_num, dtype=bool, device="cuda")
                new_metric_mask[:metric_mask.shape[0]] = metric_mask
                metric_mask = new_metric_mask
            else:
                metric_mask = metric_mask[:current_num]
        
        if filter.shape[0] != current_num:
            if filter.shape[0] < current_num:
                new_filter = torch.zeros(current_num, dtype=bool, device="cuda")
                new_filter[:filter.shape[0]] = filter
                filter = new_filter
            else:
                filter = filter[:current_num]
        
        selected_pts_mask = torch.logical_and(metric_mask, filter)
        
        if selected_pts_mask.sum() == 0:
            return
        
        # ç¡®ä¿ tmp_radii å­˜åœ¨ä¸”ç»´åº¦æ­£ç¡®
        if self.tmp_radii is None:
            self.tmp_radii = torch.zeros(current_num, device="cuda")
        elif self.tmp_radii.shape[0] != current_num:
            new_tmp_radii = torch.zeros(current_num, device="cuda")
            copy_len = min(self.tmp_radii.shape[0], current_num)
            new_tmp_radii[:copy_len] = self.tmp_radii[:copy_len]
            self.tmp_radii = new_tmp_radii
        
        new_xyz = self._xyz[selected_pts_mask]
        new_features_dc = self._features_dc[selected_pts_mask]
        new_features_rest = self._features_rest[selected_pts_mask]
        new_opacities = self._opacity[selected_pts_mask]
        new_scaling = self._scaling[selected_pts_mask]
        new_rotation = self._rotation[selected_pts_mask]
        new_tmp_radii = self.tmp_radii[selected_pts_mask]

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest, 
                                  new_opacities, new_scaling, new_rotation, new_tmp_radii)

    def densify_and_prune_fastgs(self, max_screen_size, min_opacity, extent, radii, args, importance_score = None, pruning_score = None):
        
        ''' 
            Densification and Pruning based on FastGS criteria:
            1.  The gaussians candidate for densification are selected based on the gradient of their position first.
            2.  Then, based on their average metric score (computed over multiple sampled views), they are either densified (cloned) or split.
                This is our main contribution compared to the vanilla 3DGS.
            3.  Finally, gaussians with low opacity or very large size are pruned.
        '''
        # åœ¨å¼€å§‹å‰å¼ºåˆ¶åŒæ­¥ç¼“å†²åŒº
        self.force_sync_buffers()
        
        grad_vars = self.xyz_gradient_accum / self.denom
        grad_vars[grad_vars.isnan()] = 0.0
        self.tmp_radii = radii

        grads_abs = self.xyz_gradient_accum_abs / self.denom
        grads_abs[grads_abs.isnan()] = 0.0

        grad_qualifiers = torch.where(torch.norm(grad_vars, dim=-1) >= args.grad_thresh, True, False)
        grad_qualifiers_abs = torch.where(torch.norm(grads_abs, dim=-1) >= args.grad_abs_thresh, True, False)
        clone_qualifiers = torch.max(self.get_scaling, dim=1).values <= args.dense*extent
        split_qualifiers = torch.max(self.get_scaling, dim=1).values > args.dense*extent

        all_clones = torch.logical_and(clone_qualifiers, grad_qualifiers)
        all_splits = torch.logical_and(split_qualifiers, grad_qualifiers_abs)

        # This is our multi-view consisent metric for densification
        # We use this metric to further filter the candidates for densification, which is similar to taming 3dgs.
        metric_mask = importance_score > 5

        self.densify_and_clone_fastgs(metric_mask, all_clones)
        self.densify_and_split_fastgs(metric_mask, all_splits)

        prune_mask = (self.get_opacity < min_opacity).squeeze()
        if max_screen_size:
            big_points_vs = self.max_radii2D > max_screen_size
            big_points_ws = self.get_scaling.max(dim=1).values > 0.1 * extent
            prune_mask = torch.logical_or(torch.logical_or(prune_mask, big_points_vs), big_points_ws)

        scores = 1 - pruning_score 
        to_remove = torch.sum(prune_mask)
        remove_budget = int(0.5 * to_remove)

        # The budget is not necessary for our method.
        if remove_budget:
            n_init_points = self.get_xyz.shape[0]
            padded_importance = torch.zeros((n_init_points), dtype=torch.float32)
            # ç¡®ä¿ scores ç»´åº¦æ­£ç¡®
            if scores.shape[0] <= n_init_points:
                padded_importance[:scores.shape[0]] = 1 / (1e-6 + scores.squeeze())
            else:
                padded_importance = 1 / (1e-6 + scores[:n_init_points].squeeze())
            
            selected_pts_mask = torch.zeros_like(padded_importance, dtype=bool, device="cuda")
            try:
                sampled_indices = torch.multinomial(padded_importance, remove_budget, replacement=False)
                selected_pts_mask[sampled_indices] = True
                final_prune = torch.logical_and(prune_mask, selected_pts_mask)
                self.prune_points(final_prune)
            except:
                # å¦‚æœé‡‡æ ·å¤±è´¥ï¼Œå›é€€åˆ°ç®€å•å‰ªæ
                if prune_mask.any():
                    self.prune_points(prune_mask)
        else:
            if prune_mask.any():
                self.prune_points(prune_mask)
        
        opacities_new = inverse_sigmoid(torch.min(self.get_opacity, torch.ones_like(self.get_opacity)*0.8))
        optimizable_tensors = self.replace_tensor_to_optimizer(opacities_new, "opacity")
        self._opacity = optimizable_tensors["opacity"]
        self.tmp_radii = None

        torch.cuda.empty_cache()

    def add_densification_stats(self, viewspace_point_tensor, update_filter):
        self.xyz_gradient_accum[update_filter] += torch.norm(viewspace_point_tensor.grad[update_filter,:2], dim=-1, keepdim=True)
        self.xyz_gradient_accum_abs[update_filter] += torch.norm(viewspace_point_tensor.grad[update_filter, 2:], dim=-1, keepdim=True)
        self.denom[update_filter] += 1

    def final_prune_fastgs(self, min_opacity, pruning_score = None):
        """Final-stage pruning: remove Gaussians based on opacity and multi-view consistency.
        In the final stage we remove Gaussians that have low opacity or that are flagged by
        our multi-view reconstruction consistency metric (provided as `pruning_score`)."""
        prune_mask = (self.get_opacity < min_opacity).squeeze() 
        scores_mask = pruning_score > 0.9
        final_prune = torch.logical_or(prune_mask, scores_mask)
        self.prune_points(final_prune)

    # ============== å¼ºåˆ¶åŒæ­¥ç¼“å†²åŒºçš„æ–¹æ³• ==============

    def force_sync_buffers(self):
        """å¼ºåˆ¶åŒæ­¥æ‰€æœ‰ç¼“å†²åŒºåˆ°å½“å‰ç‚¹æ•°"""
        current_num = self.get_xyz.shape[0]

        # åŒæ­¥xyz_gradient_accum
        if self.xyz_gradient_accum.shape[0] != current_num:
            new_accum = torch.zeros((current_num, 1), device="cuda")
            copy_len = min(self.xyz_gradient_accum.shape[0], current_num)
            new_accum[:copy_len] = self.xyz_gradient_accum[:copy_len]
            self.xyz_gradient_accum = new_accum

        # åŒæ­¥xyz_gradient_accum_abs
        if self.xyz_gradient_accum_abs.shape[0] != current_num:
            new_accum_abs = torch.zeros((current_num, 1), device="cuda")
            copy_len = min(self.xyz_gradient_accum_abs.shape[0], current_num)
            new_accum_abs[:copy_len] = self.xyz_gradient_accum_abs[:copy_len]
            self.xyz_gradient_accum_abs = new_accum_abs

        # åŒæ­¥denom
        if self.denom.shape[0] != current_num:
            new_denom = torch.zeros((current_num, 1), device="cuda")
            copy_len = min(self.denom.shape[0], current_num)
            new_denom[:copy_len] = self.denom[:copy_len]
            self.denom = new_denom

        # åŒæ­¥max_radii2D
        if self.max_radii2D.shape[0] != current_num:
            new_max = torch.zeros(current_num, device="cuda")
            copy_len = min(self.max_radii2D.shape[0], current_num)
            new_max[:copy_len] = self.max_radii2D[:copy_len]
            self.max_radii2D = new_max

        # åŒæ­¥tmp_radii
        if hasattr(self, 'tmp_radii') and self.tmp_radii is not None:
            if self.tmp_radii.shape[0] != current_num:
                new_tmp = torch.zeros(current_num, device="cuda")
                copy_len = min(self.tmp_radii.shape[0], current_num)
                new_tmp[:copy_len] = self.tmp_radii[:copy_len]
                self.tmp_radii = new_tmp

    # ============== è¯­ä¹‰å¢å¯†ç›¸å…³æ–¹æ³•ï¼ˆå¯é€‰ï¼‰ ==============

    def densify_semantic_regions(self, points_mask, args, extent, densify_factor=2.0):
        """
        å¯¹æ¨¡ç³ŠåŒºåŸŸè¿›è¡Œå¢å¯†ï¼ˆç¬¬ä¸€é˜¶æ®µï¼‰
        - åªåˆ†è£‚ï¼Œä¸å‰ªæ
        - åŸºäºæ¢¯åº¦é€‰æ‹©å€™é€‰ç‚¹

        Args:
            points_mask: å¸ƒå°”å¼ é‡ï¼Œè¡¨ç¤ºå“ªäº›é«˜æ–¯ç‚¹éœ€è¦å¢å¯†
            args: ä¼˜åŒ–å‚æ•°
            extent: åœºæ™¯èŒƒå›´
            densify_factor: å¢å¯†å¼ºåº¦å› å­

        Returns:
            net_change: å‡€å¢ç‚¹æ•°
        """
        if points_mask is None or points_mask.sum() == 0:
            return 0

        before_densify = self.get_xyz.shape[0]

        print(f"Phase 1 - Semantic densification: {points_mask.sum().item()} candidate points")

        if not hasattr(self, 'tmp_radii') or self.tmp_radii is None:
            self.tmp_radii = torch.zeros(self.get_xyz.shape[0], device="cuda")

        # å¯¹é½maskç»´åº¦
        current_num_points = self.get_xyz.shape[0]
        if points_mask.shape[0] != current_num_points:
            if points_mask.shape[0] < current_num_points:
                new_mask = torch.zeros(current_num_points, dtype=bool, device="cuda")
                new_mask[:points_mask.shape[0]] = points_mask
                points_mask = new_mask
            else:
                points_mask = points_mask[:current_num_points]

        # è·å–æ‰€æœ‰å€™é€‰ç‚¹ä¸­å°ºå¯¸å¤§çš„ç‚¹ï¼ˆéœ€è¦åˆ†è£‚çš„ï¼‰
        split_qualifiers = torch.max(self.get_scaling, dim=1).values > args.dense * extent
        semantic_splits_all = torch.logical_and(split_qualifiers, points_mask)

        if semantic_splits_all.sum() == 0:
            print(f"  - No split candidates found")
            return 0

        # è·å–æ‰€æœ‰åˆ†è£‚å€™é€‰ç‚¹çš„ç´¢å¼•
        split_indices = torch.where(semantic_splits_all)[0]

        # è®¡ç®—æ¢¯åº¦ï¼ˆä½¿ç”¨ç´¯ç§¯æ¢¯åº¦ï¼‰
        if hasattr(self, 'xyz_gradient_accum') and self.denom is not None:
            grad_norm = torch.norm(self.xyz_gradient_accum[split_indices] /
                                   (self.denom[split_indices] + 1e-8), dim=-1)
        else:
            grad_norm = torch.ones(len(split_indices), device="cuda")

        # æŒ‰æ¢¯åº¦é™åºæ’åºï¼ˆæ¢¯åº¦å¤§çš„ä¼˜å…ˆåˆ†è£‚ï¼‰
        sorted_indices = split_indices[torch.argsort(grad_norm, descending=True)]

        # åˆ›å»ºåˆ†è£‚mask
        split_mask = torch.zeros_like(points_mask)
        split_mask[sorted_indices] = True

        print(f"  - Split candidates: {semantic_splits_all.sum()} points, "
              f"splitting all {split_mask.sum()} points")

        # æ‰§è¡Œåˆ†è£‚ï¼ˆä¸å‰ªæï¼‰
        self._densify_split_semantic_no_prune(split_mask, densify_factor)
        print(f"  - Split {split_mask.sum()} points")

        after_all = self.get_xyz.shape[0]
        net_change = after_all - before_densify

        if after_all != before_densify:
            self.tmp_radii = torch.zeros(after_all, device="cuda")
            print(f"  - Net change: {net_change} points (now: {after_all})")

        return net_change

    def refine_difference_regions(self, points_mask, args, extent, densify_factor=2.0, prune_after=False,
                                  target_points=None):
        """
        å¯¹å·®å¼‚åŒºåŸŸè¿›è¡Œå±€éƒ¨ç»†åŒ–ï¼ˆç¬¬äºŒé˜¶æ®µï¼‰
        - å¤§å°ºå¯¸ç‚¹ï¼šåˆ†è£‚
        - å°å°ºå¯¸ç‚¹ï¼šå…‹éš†ï¼ˆæ ¹æ®æ¢¯åº¦å†³å®šæ•°é‡ï¼‰
        - å¦‚æœæä¾›target_pointsï¼Œåªä¼šåœ¨æœ€åæ£€æŸ¥å¹¶å¼ºåˆ¶å‰ªæåˆ°ç›®æ ‡ç‚¹æ•°

        Args:
            points_mask: å¸ƒå°”å¼ é‡ï¼Œè¡¨ç¤ºå“ªäº›é«˜æ–¯ç‚¹éœ€è¦å¤„ç†
            args: ä¼˜åŒ–å‚æ•°
            extent: åœºæ™¯èŒƒå›´
            densify_factor: å¢å¯†å¼ºåº¦å› å­
            prune_after: å›ºå®šä¸ºFalseï¼Œè¡¨ç¤ºä¸æ‰§è¡Œå¸¸è§„å‰ªæ
            target_points: ç›®æ ‡æ€»ç‚¹æ•°ä¸Šé™

        Returns:
            net_change: å‡€å¢ç‚¹æ•°
        """
        if points_mask is None or points_mask.sum() == 0:
            return 0

        before_densify = self.get_xyz.shape[0]
        total_candidates = points_mask.sum().item()
        print(f"Phase 2 - Refining difference regions: {total_candidates} candidate points")

        if not hasattr(self, 'tmp_radii') or self.tmp_radii is None:
            self.tmp_radii = torch.zeros(self.get_xyz.shape[0], device="cuda")

        # å¯¹é½maskç»´åº¦
        current_num_points = self.get_xyz.shape[0]
        if points_mask.shape[0] != current_num_points:
            if points_mask.shape[0] < current_num_points:
                new_mask = torch.zeros(current_num_points, dtype=bool, device="cuda")
                new_mask[:points_mask.shape[0]] = points_mask
                points_mask = new_mask
            else:
                points_mask = points_mask[:current_num_points]

        # è·å–å·®å¼‚åŒºåŸŸå†…çš„æ‰€æœ‰ç‚¹ç´¢å¼•
        diff_indices = torch.where(points_mask)[0]

        if len(diff_indices) == 0:
            return 0

        # è·å–è¿™äº›ç‚¹çš„å°ºåº¦ï¼ŒåŒºåˆ†å¤§å°ºå¯¸å’Œå°å°ºå¯¸
        scales = torch.max(self.get_scaling[diff_indices], dim=1).values
        split_qualifiers = scales > args.dense * extent  # å¤§å°ºå¯¸ -> åˆ†è£‚
        clone_qualifiers = ~split_qualifiers  # å°å°ºå¯¸ -> å…‹éš†

        total_split = 0
        total_clone = 0

        # ä¿å­˜åˆ†è£‚åéœ€è¦æ›´æ–°çš„ä¿¡æ¯
        split_done = False

        # ===== ç¬¬ä¸€æ­¥ï¼šå¤„ç†å¤§å°ºå¯¸ç‚¹ï¼ˆåˆ†è£‚ï¼‰ =====
        if split_qualifiers.sum() > 0:
            split_indices = diff_indices[split_qualifiers]
            split_mask = torch.zeros_like(points_mask)
            split_mask[split_indices] = True

            print(f"  - Split candidates: {len(split_indices)} large points")
            self._densify_split_semantic(split_mask, densify_factor)
            total_split = split_mask.sum().item()
            split_done = True
            print(f"    Split {total_split} points")

        # ===== ç¬¬äºŒæ­¥ï¼šå¤„ç†å°å°ºå¯¸ç‚¹ï¼ˆå…‹éš†ï¼ŒæŒ‰æ¢¯åº¦å†³å®šæ•°é‡ï¼‰ =====
        if clone_qualifiers.sum() > 0:
            if split_done:
                # å¦‚æœå·²ç»æ‰§è¡Œäº†åˆ†è£‚ï¼Œé‡æ–°è®¡ç®—clone_indices
                current_num_points = self.get_xyz.shape[0]
                original_clone_indices = diff_indices[clone_qualifiers]
                valid_mask = original_clone_indices < current_num_points
                valid_clone_indices = original_clone_indices[valid_mask]

                if len(valid_clone_indices) > 0:
                    # è®¡ç®—è¿™äº›ç‚¹çš„æ¢¯åº¦
                    if hasattr(self, 'xyz_gradient_accum') and self.denom is not None:
                        grad_norm = torch.norm(self.xyz_gradient_accum[valid_clone_indices] /
                                               (self.denom[valid_clone_indices] + 1e-8), dim=-1)
                        if grad_norm.max() > 0:
                            grad_norm = grad_norm / grad_norm.max()
                    else:
                        grad_norm = torch.ones(len(valid_clone_indices), device="cuda") * 0.5

                    # æ ¹æ®æ¢¯åº¦å†³å®šå…‹éš†æ•°é‡
                    clone_counts = (grad_norm * 2 + 1).int()  # èŒƒå›´ï¼š1-3

                    # é€ç‚¹å…‹éš†
                    total_clones_this_round = 0
                    for idx, count in zip(valid_clone_indices, clone_counts):
                        if count > 0:
                            mask = torch.zeros(current_num_points, dtype=bool, device="cuda")
                            mask[idx] = True
                            self._densify_clone_semantic(mask, densify_factor=count.item())
                            total_clones_this_round += count.item()

                    total_clone = total_clones_this_round
                    print(f"  - Clone candidates: {len(valid_clone_indices)} small points, "
                          f"cloned {total_clone} copies")
            else:
                # æ²¡æœ‰åˆ†è£‚ï¼Œç›´æ¥ç”¨åŸæ¥çš„indices
                clone_indices = diff_indices[clone_qualifiers]

                # è®¡ç®—æ¢¯åº¦åˆ†æ•°
                if hasattr(self, 'xyz_gradient_accum') and self.denom is not None:
                    grad_norm = torch.norm(self.xyz_gradient_accum[clone_indices] /
                                           (self.denom[clone_indices] + 1e-8), dim=-1)
                    if grad_norm.max() > 0:
                        grad_norm = grad_norm / grad_norm.max()
                else:
                    grad_norm = torch.ones(len(clone_indices), device="cuda") * 0.5

                # æ ¹æ®æ¢¯åº¦å†³å®šå…‹éš†æ•°é‡
                clone_counts = (grad_norm * 2 + 1).int()  # èŒƒå›´ï¼š1-3

                # é€ç‚¹å…‹éš†
                total_clones_this_round = 0
                for idx, count in zip(clone_indices, clone_counts):
                    if count > 0:
                        mask = torch.zeros_like(points_mask)
                        mask[idx] = True
                        self._densify_clone_semantic(mask, densify_factor=count.item())
                        total_clones_this_round += count.item()

                total_clone = total_clones_this_round
                print(f"  - Clone candidates: {len(clone_indices)} small points, "
                      f"cloned {total_clone} copies")

        # ===== ç¬¬ä¸‰æ­¥ï¼šæ£€æŸ¥ç›®æ ‡ç‚¹æ•°é™åˆ¶ =====
        after_densify = self.get_xyz.shape[0]
        
        if target_points is not None and after_densify > target_points:
            print(f"  - Current points {after_densify} exceeds target {target_points}, enforcing limit")
            
            # ç®€å•çš„å¼ºåˆ¶å‰ªæ - åŸºäºè´¨é‡åˆ†æ•°
            need_prune = after_densify - target_points
            
            # è®¡ç®—è´¨é‡åˆ†æ•°ï¼ˆåˆ†æ•°è¶Šé«˜è¶Šè¯¥è¢«å‰ªæï¼‰
            quality_score = torch.zeros(after_densify, device="cuda")
            
            # é€æ˜åº¦åˆ†æ•°ï¼ˆé€æ˜åº¦è¶Šä½ï¼Œåˆ†æ•°è¶Šé«˜ï¼‰
            opacity = self.get_opacity.squeeze()
            quality_score += (1.0 - opacity) * 2.0
            
            # å°ºå¯¸åˆ†æ•°ï¼ˆå°ºå¯¸è¶Šå¤§ï¼Œåˆ†æ•°è¶Šé«˜ï¼‰
            size_score = self.get_scaling.max(dim=1).values / (0.1 * extent)
            quality_score += size_score.clamp(max=2.0)
            
            # å±å¹•ç©ºé—´å¤§å°åˆ†æ•°
            if hasattr(self, 'max_radii2D') and self.max_radii2D is not None:
                screen_score = self.max_radii2D / 15.0
                quality_score += screen_score.clamp(max=2.0)
            
            # æ‰¾åˆ°è´¨é‡åˆ†æ•°æœ€é«˜çš„ need_prune ä¸ªç‚¹
            _, indices_to_prune = torch.topk(quality_score, min(need_prune, len(quality_score)), largest=True)
            
            force_prune_mask = torch.zeros(after_densify, dtype=bool, device="cuda")
            force_prune_mask[indices_to_prune] = True
            self.prune_points(force_prune_mask)
            
            print(f"  - Enforced target points limit, removed {need_prune} points")

        # è®¡ç®—å‡€å˜åŒ–
        after_all = self.get_xyz.shape[0]
        net_change = after_all - before_densify

        if after_all != before_densify:
            self.tmp_radii = torch.zeros(after_all, device="cuda")
            print(f"  - Net change: {net_change} points (now: {after_all})")

        return net_change

    def _densify_clone_semantic(self, mask, densify_factor=2.0):
        """å…‹éš†è¯­ä¹‰åŒºåŸŸå†…çš„ç‚¹"""
        N = int(densify_factor)

        # ç¡®ä¿maskçš„ç»´åº¦åŒ¹é…
        if mask.shape[0] != self._xyz.shape[0]:
            if mask.shape[0] < self._xyz.shape[0]:
                new_mask = torch.zeros(self._xyz.shape[0], dtype=bool, device="cuda")
                new_mask[:mask.shape[0]] = mask
                mask = new_mask
            else:
                mask = mask[:self._xyz.shape[0]]

        if mask.sum() == 0:
            return

        new_xyz = self._xyz[mask].repeat(N, 1)
        new_features_dc = self._features_dc[mask].repeat(N, 1, 1)
        new_features_rest = self._features_rest[mask].repeat(N, 1, 1)
        new_opacities = self._opacity[mask].repeat(N, 1)
        new_scaling = self._scaling[mask].repeat(N, 1)
        new_rotation = self._rotation[mask].repeat(N, 1)

        if hasattr(self, 'tmp_radii') and self.tmp_radii is not None:
            new_tmp_radii = self.tmp_radii[mask].repeat(N)
        else:
            new_tmp_radii = torch.ones(N * mask.sum(), device="cuda")

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest,
                                   new_opacities, new_scaling, new_rotation, new_tmp_radii)

    def _densify_split_semantic(self, mask, densify_factor=2.0):
        """åˆ†è£‚è¯­ä¹‰åŒºåŸŸå†…çš„ç‚¹ï¼ˆæ¯ä¸ªç‚¹åˆ†è£‚æˆ2ä¸ªï¼Œå¹¶å‰ªæåŸå§‹ç‚¹ï¼‰"""
        N = 2

        # ç¡®ä¿maskçš„ç»´åº¦åŒ¹é…
        if mask.shape[0] != self._xyz.shape[0]:
            if mask.shape[0] < self._xyz.shape[0]:
                new_mask = torch.zeros(self._xyz.shape[0], dtype=bool, device="cuda")
                new_mask[:mask.shape[0]] = mask
                mask = new_mask
            else:
                mask = mask[:self._xyz.shape[0]]

        if mask.sum() == 0:
            return

        stds = self.get_scaling[mask].repeat(N, 1)
        means = torch.zeros((stds.size(0), 3), device="cuda")
        samples = torch.normal(mean=means, std=stds)
        rots = build_rotation(self._rotation[mask]).repeat(N, 1, 1)
        new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[mask].repeat(N, 1)

        scale_factor = 0.8 * N / densify_factor
        new_scaling = self.scaling_inverse_activation(
            self.get_scaling[mask].repeat(N, 1) / scale_factor
        )

        new_rotation = self._rotation[mask].repeat(N, 1)
        new_features_dc = self._features_dc[mask].repeat(N, 1, 1)
        new_features_rest = self._features_rest[mask].repeat(N, 1, 1)
        new_opacity = self._opacity[mask].repeat(N, 1)

        if hasattr(self, 'tmp_radii') and self.tmp_radii is not None:
            new_tmp_radii = self.tmp_radii[mask].repeat(N)
        else:
            new_tmp_radii = torch.ones(N * mask.sum(), device="cuda")

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest,
                                   new_opacity, new_scaling, new_rotation, new_tmp_radii)

        prune_filter = torch.cat((mask, torch.zeros(N * mask.sum(), device="cuda", dtype=bool)))
        self.prune_points(prune_filter)

    def _densify_split_semantic_no_prune(self, mask, densify_factor=2.0):
        """åˆ†è£‚è¯­ä¹‰åŒºåŸŸå†…çš„ç‚¹ï¼ˆæ¯ä¸ªç‚¹åˆ†è£‚æˆ2ä¸ªï¼Œä½†ä¿ç•™åŸå§‹ç‚¹ - ç”¨äºç¬¬ä¸€é˜¶æ®µï¼‰"""
        N = 2

        # ç¡®ä¿maskçš„ç»´åº¦åŒ¹é…
        if mask.shape[0] != self._xyz.shape[0]:
            if mask.shape[0] < self._xyz.shape[0]:
                new_mask = torch.zeros(self._xyz.shape[0], dtype=bool, device="cuda")
                new_mask[:mask.shape[0]] = mask
                mask = new_mask
            else:
                mask = mask[:self._xyz.shape[0]]

        if mask.sum() == 0:
            return

        stds = self.get_scaling[mask].repeat(N, 1)
        means = torch.zeros((stds.size(0), 3), device="cuda")
        samples = torch.normal(mean=means, std=stds)
        rots = build_rotation(self._rotation[mask]).repeat(N, 1, 1)
        new_xyz = torch.bmm(rots, samples.unsqueeze(-1)).squeeze(-1) + self.get_xyz[mask].repeat(N, 1)

        scale_factor = 0.8 * N / densify_factor
        new_scaling = self.scaling_inverse_activation(
            self.get_scaling[mask].repeat(N, 1) / scale_factor
        )

        new_rotation = self._rotation[mask].repeat(N, 1)
        new_features_dc = self._features_dc[mask].repeat(N, 1, 1)
        new_features_rest = self._features_rest[mask].repeat(N, 1, 1)
        new_opacity = self._opacity[mask].repeat(N, 1)

        if hasattr(self, 'tmp_radii') and self.tmp_radii is not None:
            new_tmp_radii = self.tmp_radii[mask].repeat(N)
        else:
            new_tmp_radii = torch.ones(N * mask.sum(), device="cuda")

        self.densification_postfix(new_xyz, new_features_dc, new_features_rest,
                                   new_opacity, new_scaling, new_rotation, new_tmp_radii)

       
